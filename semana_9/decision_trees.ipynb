{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Árvores de Decisão**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importe as principais bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# desabilita os warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TOC:**\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) [Introdução](#intro)\n",
    "- 2) [Arvore de decisao - Exemplo Teorico](#exemplo_teorico)\n",
    "- 3) [Resampling](#resampling)\n",
    "- 4) [Utilizando dados categóricos](#categorical)\n",
    "    - 4.1) [One Hot Encoding](#one_hot)\n",
    "    - 4.2) [Ordinal Encoding](#ordinal)\n",
    "- 5) [Arvore de decisao - Exemplo pratico](#exemplo_pratico)\n",
    "    - 5.1) [Sem oversampling](#without)\n",
    "    - 5.2) [Com oversampling](#with)\n",
    "    - 5.3) [Visualizando a árvore de decisão](#visu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1) **Introdução** <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "Estrutura de uma árvore de decisão:\n",
    "\n",
    "<center><img src=\"https://i1.wp.com/www.vooo.pro/insights/wp-content/uploads/2016/12/RDS-Vooo_insights-Tutorial_arvore_de_decisao_02.jpg?resize=640%2C371&ssl=1\" width=300></center>\n",
    "\n",
    "**Exemplo:**\n",
    "\n",
    "<center><img src=\"https://didatica.tech/wp-content/uploads/2020/07/image-3.png\" width=300></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) **Arvore de decisao - Exemplo Teórico** <a class=\"anchor\" id=\"exemplo_teorico\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exemplo__\n",
    "\n",
    "Digamos que uma amostra de 30 alunos tem duas variáveis: Sexo (menino ou menina), Classe (IX ou X). \n",
    "\n",
    "Digamos também que 15 destes 30 jogam tênis no recreio. \n",
    "\n",
    "Uma pergunta natural é: **qual feature utilizamos para fazer a quebra do nó raiz: sexo ou classe?**\n",
    "\n",
    "Há duas quebras possíveis:\n",
    "\n",
    "<font color=\"red\"> <b>Mudar de 120 para 20</b></font>\n",
    "<center><img src=\"figures/decision_tree.png\" width=400>></center>\n",
    "\n",
    "Vemos que, **dependendo da feature que utilizamos pra fazer a quebra**, conseguimos **graus de separações diferentes dos dados com relação ao target**:\n",
    "\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th colspan=\"4\"><center>Sexo</center></th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td colspan=\"2\"><center>Meninas</center></td>\n",
    "    <td colspan=\"2\"><center>Meninos</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center>jogam tênis</center></td>\n",
    "    <td><center>NÃO jogam tênis</center></td>\n",
    "    <td><center>jogam tênis</center></td>\n",
    "    <td><center>NÃO jogam tênis</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center>2</center></td>\n",
    "    <td><center>8</center></td>\n",
    "    <td><center>13</center></td>\n",
    "    <td><center>7</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"2\"><center>10</center></td>\n",
    "    <td colspan=\"2\"><center>20</center></td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th colspan=\"4\"><center>Classe</center></th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td colspan=\"2\"><center>IX</center></td>\n",
    "    <td colspan=\"2\"><center>X</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center>jogam tênis</center></td>\n",
    "    <td><center>NÃO jogam tênis</center></td>\n",
    "    <td><center>jogam tênis</center></td>\n",
    "    <td><center>NÃO jogam tênis</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><center>6</center></td>\n",
    "    <td><center>8</center></td>\n",
    "    <td><center>9</center></td>\n",
    "    <td><center>7</center></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"2\"><center>14</center></td>\n",
    "    <td colspan=\"2\"><center>16</center></td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Como decidir qual das quebrar acima **separou melhor os dados com relação ao target?**\n",
    "\n",
    "Matematicamente, o modelo pode usar dois critérios diferentes para decidir como fazer as quebras na árvore: o **critério de Gini** ou o **critério da entropia**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "**Critério de Gini**\n",
    "\n",
    "A **impureza de Gini** mede o quão \"impuras\" são as folhas das árvores construídas após as quebras nos nós. O coeficiente é dado por:\n",
    "\n",
    "$$Gini(D) = 1 - \\sum{p_{i}^2}$$\n",
    "\n",
    "Onde $p_i$ são as proporções de separação do target em cada quebra.\n",
    "\n",
    "Aqui estaremos interessados **em como a impureza muda após as quebras**. Nosso objetivo será **maximizar a purificação proporcionada pela quebra nos nós** -- mais precisamente, estamos interessados em determinar **qual é a quebra que proporciona a maior purificação**.\n",
    "\n",
    "- **Impureza antes da divisão**: Como não havia separação alguma, a impureza era dada simplesmente pelo balanço natural dos dados: \n",
    "\n",
    "$$G(\\text{pré-divisão}) = 1 - ((15/30)^2 + (15/30)^2) = 0.5$$\n",
    "\n",
    "Temos duas quebras possíveis:\n",
    "\n",
    "- Divisão por **sexo**: após a divisão dos dados pela feature **sexo**, passamos a ter as seguintes impurezas, segundo a tabela acima: \n",
    "\n",
    "    - $G(\\text{meninas}) = 1 - (\\frac{2}{10}^2 + \\frac{8}{10}^2) = 0.319$\n",
    "    \n",
    "    - $G(\\text{meninos}) = 1 - ( \\frac{13}{20}^2 + \\frac{7}{20}^2) = 0.454$\n",
    "    \n",
    "    Ou seja, após a divisão, a impureza total passa a ser a média ponderada: \n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $G(\\text{pós-divisão}) = \\frac{10}{30} \\cdot G(\\text{meninas}) + \\frac{20}{30} \\cdot G(\\text{meninos})\n",
    "    = 0.33 \\times 0.319 + 0.66 \\times 0.454\n",
    "    = 0.40491$\n",
    "    \n",
    "    Assim, **a perda de impureza proporcionada pela quebra** dos dados segundo a feature **sexo** é de:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $\\Delta G_{\\text{sexo}} = G(\\text{pré-divisão}) - G(\\text{pós-divisão}) = 0.5 - 0.40491 = $ **0.095**\n",
    "    \n",
    "    \n",
    "<br> \n",
    "\n",
    "\n",
    "- Divisão por **classe**: após a divisão dos dados pela feature **classe**, passamos a ter as seguintes impurezas, segundo a tabela acima:\n",
    "\n",
    "    - $G(\\text{IX}) = 1 - (\\frac{6}{14}^2 + \\frac{8}{14}^2) = 0.489$\n",
    "    \n",
    "    - $G(\\text{X}) = 1 - ( \\frac{9}{16}^2 + \\frac{7}{16}^2) = 0.492$\n",
    "    \n",
    "    Ou seja, após a divisão, a impureza total passa a ser a média ponderada: \n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $G(\\text{pós-divisão}) = \\frac{14}{30} \\times G(\\text{IX}) + \\frac{16}{30} \\times G(\\text{X})\n",
    "    = 0.46 \\times 0.489 + 0.53 \\times 0.492\n",
    "    = 0.4857$\n",
    "    \n",
    "    Assim, **a perda de impureza proporcionada pela quebra** dos dados segundo a feature **classe** é de:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $\\Delta G_{\\text{classe}} = G(\\text{pré-divisão}) - G(\\text{pós-divisão}) = 0.5 - 0.4857 = $ **0.014**\n",
    "  \n",
    "Agora, como escolher a melhor quebra?\n",
    "\n",
    "> O **critério de Gini** consiste em **escolher a quebra que proporciona a maior perda de impureza**, ou, equivalentemente, **a maior purificação**.\n",
    "\n",
    "Assim, a divisão a ser escolhida seria por **sexo**. \n",
    "\n",
    "Depois, aplica-se o mesmo procedimento para os nós resultantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "\n",
    "**Critério de entropia**\n",
    "\n",
    "A **entropia** é uma quantidade definida em física e teoria da informação com o objetivo de quantificar **o grau de desordem de um sistema**, ou, equivalentemente, **o quanto de informação se tem sobre determinado sistema**.\n",
    "\n",
    "A entropia é dada por:\n",
    "\n",
    " $$E = -\\sum{p_{i} \\times \\log_{2}{p_{i}}}$$\n",
    " \n",
    " \n",
    "Onde $p_i$ são as proporções de separação do target em cada quebra.\n",
    "\n",
    "Aqui estaremos interessados **em como a impureza muda após as quebras**. \n",
    " \n",
    "Aqui também estaremos interessados **em como a entropia muda após as quebras**. Nosso objetivo será **maximizar o ganho de informação proporcionado pela quebra nos nós** -- mais precisamente, estamos interessados em determinar **qual é a quebra que proporciona o maior ganho de informação**.\n",
    "\n",
    "- **Entropia antes da divisão**: \n",
    "\n",
    "$$E(pré-divisão) = \\frac{15}{10}log_{2}{\\frac{15}{10}} + \\frac{15}{10}log_{2}{\\frac{15}{10}} = 1$$\n",
    "\n",
    "\n",
    "Temos duas quebras possíveis:\n",
    "\n",
    "- Divisão por sexo: \n",
    "\n",
    "    - $E(\\text{meninas}) = -1 \\times (\\frac{2}{10} \\log_{2}\\frac{2}{10} + \\frac{8}{10} \\log_{2}\\frac{8}{10}) = 0.721$\n",
    "    - $E(\\text{meninos}) = -1 \\times (\\frac{13}{20} \\log_{2}\\frac{13}{20} + \\frac{7}{20} \\log_{2}\\frac{7}{20}) = 0.934$\n",
    "    \n",
    "    A entropia ponderada após a divisão por **sexo** é:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $E(\\text{pós-divisão}) = \\frac{10}{30} \\times E(\\text{meninas}) + \\frac{20}{30} \\times E(\\text{meninos}) =  0.863$\n",
    "    \n",
    "    Assim, o ganho de informação após a divisão por **sexo** é:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $\\Delta E_{\\text{sexo}} = E(\\text{pré-divisão}) - E(\\text{pós-divisão}) = 1 - 0.863 =$ **0.137**\n",
    "\n",
    "<br>\n",
    "\n",
    "- Divisão por classe:\n",
    "\n",
    "    - $E(\\text{IX}) = -1 \\times (\\frac{6}{14} \\log_{2}\\frac{6}{14} + \\frac{8}{14} \\log_{2}\\frac{8}{14}) = 0.985$\n",
    "    - $E(\\text{X}) = -1 \\times (\\frac{9}{16} \\log_{2}\\frac{9}{16} + \\frac{7}{16} \\log_{2}\\frac{7}{16}) = 0.988$\n",
    "    \n",
    "    A entropia ponderada após a divisão por **classe** é:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $E(\\text{pós-divisão}) = \\frac{10}{30} \\times E(\\text{IX}) + \\frac{20}{30} \\times E(\\text{X}) =  0.986$\n",
    "    \n",
    "    Assim, o ganho de informação após a divisão por **classe** é:\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    - $\\Delta E_{\\text{classe}} = E(\\text{pré-divisão}) - E(\\text{pós-divisão}) = 1 - 0.986 =$ **0.014**\n",
    "\n",
    "Também pela entropia, a divisão a ser escolhida seria por **sexo**. \n",
    "\n",
    "Depois, aplica-se o mesmo procedimento para os nós resultantes, até obter-se nós puros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "__Qual a diferença entre os dois critérios?__\n",
    "\n",
    "A origem, e pequenas diferenças computacionais. \n",
    "\n",
    "Apesar das medidas serem semelhantes, é possível que haja sim diferenças nos resultados gerados por cada um deles!\n",
    "\n",
    "<center><img src=\"https://qph.fs.quoracdn.net/main-qimg-3f3484dc9513748c3283fa0d1d996e82\" width=400>\n",
    "</center>\n",
    "Como dica geral: teste ambos! O Grid Search pode sempre nos ajudar a determinar qual dos dois é mais adequado em cada caso!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a nosso exemplo prático?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o exempçlo de árvore de descisão iremos utilizar um [dataset de Marketing bancário](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing). Ele demonstra valores de campanha de telemarketing de banco portugues. O objetivo e prever se o cliente assinará um termo de depósito, com base nas features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leia os dados, que devem estar em '../datasets/bank-full.csv'\n",
    "# é necessário usar o separador \";\"\n",
    "df = pd.read_csv('data/bank_full.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há um desbalanço considerável... Como podemos resolver isso?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query(\"previous<=250\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) **Resampling** <a class=\"anchor\" id=\"resampling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exitem duas técnicas principais de reamostragem: \n",
    "\n",
    "- **Oversampling:** Esse método consiste em replicar os dados da classe minoritária, até que o balanço seja alcançado:\n",
    "\n",
    "- **Undersampling:** Este método consiste em criar uma nova amostra **dos dados que estão na classe majoritária**, de modo que o balanço seja alcançado.\n",
    "\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/725/0*FeIp1t4uEcW5LmSM.png\" width=600></center>\n",
    "\n",
    "Para mais detalhes sobre estas técnicas, e como fazê-las com uma biblioteca, [clique aqui](https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/). Obs.: note que uma estratégia interessante é utilizar ambos o undersampling e o oversampling juntos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "res = RandomUnderSampler(random_state=42)\n",
    "X = df.drop(columns=\"y\")\n",
    "y = df[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = res.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45210, 16) (45210,)\n",
      "(10578, 16) (10578,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "print(X_res.shape, y_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     39921\n",
       "yes     5289\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     5289\n",
       "yes    5289\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consegue fazer um exemplo de oversampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4) **Utilizando dados categóricos** <a class=\"anchor\" id=\"categorical\"></a>\n",
    "\n",
    "Chegou o momento de aprendermos uma forma de utilizar dados categóricos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) **One-hot encoding** <a class=\"anchor\" id=\"one_hot\"></a>\n",
    "\n",
    "Outra forma extremamente comum de utilizar variáveis categóricas é através da criação de **variáveis mudas** (dummy variables)\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/2474/1*ggtP4a5YaRx6l09KQaYOnw.png\" width=500></center>\n",
    "\n",
    "Isso é facilmente feito com o pandas utilizando a função [pd.get_dummies()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45210 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_yes\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "...      ...\n",
       "45206      1\n",
       "45207      1\n",
       "45208      1\n",
       "45209      0\n",
       "45210      0\n",
       "\n",
       "[45210 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df,drop_first=True)[[\"y_yes\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas note que há uma redundância nas colunas! Para resolver isso, podemos utilizar o argumento drop_first=True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O sklearn também tem uma forma de realizar a mesma operação utilizando a classe **OneHotEncoder**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoder.fit_transform(df[\"y\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ordinal encoding** <a class=\"anchor\" id=\"ordinal\"></a>\n",
    "<center><img src=\"https://miro.medium.com/max/654/1*NUzgzszTdpLPZpeKPPf0kQ.png\" width=200></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_encoder.fit_transform(df[\"y\"].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que eles são diferentes, nesse caso como estavamos mexendo com uma variável binária eles fizeram a mesma transformação nos nossos dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) **Arvore de decisao - Exemplo Prático** <a class=\"anchor\" id=\"exemplo_pratico\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar uma pipeline que vai tratar os dados numéricos e categóricos nominais diferentemente. Além disso, vamos também utilizar uma classe que faz undersample dos dados na nossa pipeline.\n",
    "\n",
    "Obs.: Vamos utilizar [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) e [FeatureUnion](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1) **Sem oversampling** <a class=\"anchor\" id=\"without\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_nominais_cols = [\"job\", \"marital\", \"poutcome\"]\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_creation',\n",
       "                 FeatureUnion(transformer_list=[('processor_cn',\n",
       "                                                 ColumnTransformer(transformers=[('cn',\n",
       "                                                                                  Pipeline(steps=[('imputer',\n",
       "                                                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                                  ('one_hot',\n",
       "                                                                                                   OneHotEncoder(sparse=False))]),\n",
       "                                                                                  ['job',\n",
       "                                                                                   'marital',\n",
       "                                                                                   'poutcome'])])),\n",
       "                                                ('processor_n',\n",
       "                                                 ColumnTransformer(transformers=[('n',\n",
       "                                                                                  Pipeline(steps=[('imputer',\n",
       "                                                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                                  ('scaler',\n",
       "                                                                                                   StandardScaler())]),\n",
       "                                                                                  Index(['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous'], dtype='object'))]))])),\n",
       "                ('model', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns = [\"y\"])\n",
    "y = df[\"y\"].astype(\"category\").cat.codes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=y)\n",
    "\n",
    "categorical_nominal_transform = Pipeline([\n",
    "    \n",
    "                                        (\"one_hot\", OneHotEncoder(sparse=False))\n",
    "                                        ])\n",
    "preprocessor_cn = ColumnTransformer(transformers=[(\"cn\", \n",
    "                                                  categorical_nominal_transform, \n",
    "                                                  categorical_nominais_cols)])\n",
    "\n",
    "numerical_transform = Pipeline([\n",
    "    \n",
    "                              (\"scaler\", StandardScaler())\n",
    "                              ])\n",
    "preprocessor_n = ColumnTransformer(transformers=[(\"n\", \n",
    "                                                  numerical_transform, \n",
    "                                                  numeric_cols)])\n",
    "\n",
    "preprocessing = FeatureUnion([\n",
    "                            (\"processor_cn\", preprocessor_cn),\n",
    "                            (\"processor_n\", preprocessor_n)\n",
    "                            ])\n",
    "\n",
    "model = Pipeline([\n",
    "                (\"feature_creation\", preprocessing),\n",
    "                (\"model\", DecisionTreeClassifier()),\n",
    "                 ])\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     31937\n",
      "           1       1.00      1.00      1.00      4231\n",
      "\n",
      "    accuracy                           1.00     36168\n",
      "   macro avg       1.00      1.00      1.00     36168\n",
      "weighted avg       1.00      1.00      1.00     36168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_hat = model.predict(X_train)\n",
    "print(classification_report(y_train, y_train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      7984\n",
      "           1       0.37      0.41      0.39      1058\n",
      "\n",
      "    accuracy                           0.85      9042\n",
      "   macro avg       0.65      0.66      0.65      9042\n",
      "weighted avg       0.86      0.85      0.85      9042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model.predict(X_test)\n",
    "print(classification_report(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo grid_search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('feature_creation',\n",
       "                                        FeatureUnion(transformer_list=[('processor_cn',\n",
       "                                                                        ColumnTransformer(transformers=[('cn',\n",
       "                                                                                                         Pipeline(steps=[('one_hot',\n",
       "                                                                                                                          OneHotEncoder(sparse=False))]),\n",
       "                                                                                                         ['job',\n",
       "                                                                                                          'marital',\n",
       "                                                                                                          'poutcome'])])),\n",
       "                                                                       ('processor_n',\n",
       "                                                                        ColumnTransformer(transformers=[('n',\n",
       "                                                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                                                          SimpleImputer()),\n",
       "                                                                                                                         ('scaler',\n",
       "                                                                                                                          StandardScaler())]),\n",
       "                                                                                                         Index(['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous'], dtype='object'))]))])),\n",
       "                                       ('model', DecisionTreeClassifier())]),\n",
       "             param_grid={'model__max_depth': [4, 5, 6, 7]})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"model__max_depth\" : [4,5,6,7]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      7984\n",
      "           1       0.65      0.32      0.43      1058\n",
      "\n",
      "    accuracy                           0.90      9042\n",
      "   macro avg       0.78      0.65      0.69      9042\n",
      "weighted avg       0.88      0.90      0.88      9042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) **Com oversampling** <a class=\"anchor\" id=\"with\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df (meu_todo) -> X, y\n",
    "    - treino_df -> X_train, y_train\n",
    "    - test_df -> X_test, y_test\n",
    "    \n",
    "test_df -> X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "X = df.drop(columns = [\"y\"])\n",
    "y = df[\"y\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_nominais_cols = [\"job\", \"marital\", \"poutcome\"]\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "\n",
    "numeric_processor = Pipeline([(\"impute\", SimpleImputer())])\n",
    "numeric_column_transform = ColumnTransformer(transformers=[(\"numeric_processor\", \n",
    "                                                            numeric_processor, \n",
    "                                                            numeric_cols)])\n",
    "\n",
    "categorical_processor = Pipeline([(\"one_hot\", OneHotEncoder())])\n",
    "categorical_processing = ColumnTransformer(transformers=[(\"categorical_processor\", \n",
    "                                                            categorical_processor, \n",
    "                                                            categorical_nominais_cols)])\n",
    "\n",
    "main_processing = FeatureUnion([\n",
    "        (\"processamento1\", numeric_column_transform),\n",
    "        (\"processamento2\", categorical_processing)\n",
    "])\n",
    "\n",
    "model = Pipeline([\n",
    "        (\"under_sampler\", RandomUnderSampler()),\n",
    "        (\"processor\", main_processing),\n",
    "        (\"model\", DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "param_grid = {\"model__max_depth\": [4, 5, 6, 7],\n",
    "              \"model__min_samples_split\": [10, 50, 100, 1000]}\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, cv=5, refit=True, scoring=\"f1\")\n",
    "\n",
    "\n",
    "#main_processor = FeatureUnion([(\"numeric\", numeric_column_transform)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('under_sampler', RandomUnderSampler()),\n",
       "                                       ('processor',\n",
       "                                        FeatureUnion(transformer_list=[('processamento1',\n",
       "                                                                        ColumnTransformer(transformers=[('numeric_processor',\n",
       "                                                                                                         Pipeline(steps=[('impute',\n",
       "                                                                                                                          SimpleImputer())]),\n",
       "                                                                                                         Index(['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous'], dtype='object'))])),\n",
       "                                                                       ('processamento2',\n",
       "                                                                        ColumnTransformer(transformers=[('categorical_processor',\n",
       "                                                                                                         Pipeline(steps=[('one_hot',\n",
       "                                                                                                                          OneHotEncoder())]),\n",
       "                                                                                                         ['job',\n",
       "                                                                                                          'marital',\n",
       "                                                                                                          'poutcome'])]))])),\n",
       "                                       ('model', DecisionTreeClassifier())]),\n",
       "             param_grid={'model__max_depth': [4, 5, 6, 7],\n",
       "                         'model__min_samples_split': [10, 50, 100, 1000]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90      7984\n",
      "           1       0.38      0.69      0.49      1058\n",
      "\n",
      "    accuracy                           0.83      9042\n",
      "   macro avg       0.67      0.77      0.69      9042\n",
      "weighted avg       0.89      0.83      0.85      9042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = grid.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma outra forma de buscar por hiperparâmetros é através **de uma busca aleatória**, o que pode ser feito através do [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n",
    "A diferença entre este buscador e o GridSearch, é que neste caso não explicitamos a lista com os valores dos hiperparâmetros a sere, combinados, mas passamos **os valores possíveis dos hiperparâmetros, que são amostrados aleatoriamente de modo a gerar combinações aleatórias!** Aí, ao invés de tentarmos todas as combinações possíveis, testamos apenas **um número determinado de combinações aleatoriamente amostradas das distribuições!**\n",
    "\n",
    "Para mais informações sobre este método, [clique aqui!](https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-search).\n",
    "\n",
    "[Veja aqui](https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html) uma comparação entre os dois métodos.\n",
    "\n",
    "Em algumas situações, pode ser que a busca aleatória seja mais eficiente que o grid search, dado seu caráter aleatório!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) **Visualizando a árvore de decisão** <a class=\"anchor\" id=\"visu\"></a>\n",
    "\n",
    "É possível visualizar a árvore de decisão criada com o próprio sklearn!\n",
    "\n",
    "Para isso, basta usar a função `plot_tree()` do sub-módulo tree, conforme abaixo!\n",
    "\n",
    "Para mais detalhes sobre como plotar a árvore, [clique aqui](https://scikit-learn.org/stable/modules/tree.html#tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_playground",
   "language": "python",
   "name": "venv_playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
