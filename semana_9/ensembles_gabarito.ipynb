{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Aula 11 - Ensembles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## **TOC:**\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) [Métodos de Ensemble](#intro)\n",
    "- 2) [Random Forest](#random_forest)\n",
    "- 3) [Adaboost](#ada)\n",
    "- 4) [Árvores de regressão](#regression)\n",
    "- 5) [Exercicio](#exercicio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) **Métodos de Ensemble** <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "Há uma classe de algoritmos de Machine Learning, os chamados **métodos de ensemble** que tem como objetivo **combinar as predições de diversos estimadores mais simples** para gerar uma **predição final mais robusta**\n",
    "    \n",
    "Os métodos de ensemble são ainda divididos em duas classes:\n",
    "\n",
    "- **Métodos de bagging**: têm como procedimento geral construir diversos <font color=\"orange\"><b>estimadores independentes</b></font>, e tomar a média de suas predições como a predição final. O principal objetivo do método é reduzir variância, de modo que o modelo final seja melhor que todos os modelos individuais. Ex.: **random forest.**\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Métodos de boosting**: têm como procedimento geral a construção de estimadores de forma sequencial, de modo que estimadores posteriores tentam reduzir o viés do estimador conjunto, que leva em consideração estimadores anteriores. Ex.: **adaboost**.\n",
    "\n",
    "Para mais detalhes, [clique aqui!](https://scikit-learn.org/stable/modules/ensemble.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) **Random Forest** <a class=\"anchor\" id=\"random_forest\"></a>\n",
    "\n",
    "Uma técnica muito interessante baseada em árvores é o **Random Forest**.\n",
    "\n",
    "Neste modelo, são criadas varias árvores diferentes aleatoriamente, e a predição final é tomada através do voto majoritário de todas as árvores!\n",
    "\n",
    "<center><img src=\"https://i.ytimg.com/vi/goPiwckWE9M/maxresdefault.jpg\" width=700></center>\n",
    "\n",
    "O modelo de Random Forest utiliza os conceitos de **bootstraping** e **aggregation** (ou então, o procedimento composto **bagging**) para criar um modelo composto que é melhor que uma única árvore!\n",
    "\n",
    "<center><img src=\"https://c.mql5.com/2/33/image1__1.png\" width=600></center>\n",
    "\n",
    "Para maiores detalhes sobre como o modelo funciona, sugiro os vídeos do canal [StatQuest](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ). \n",
    "\n",
    "Obs.: toda a [playlist de machine learning](https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF) é muitíssimo interessante, com vídeos super claros e ilustrativos! Além disso, há outros vídeos de estatística que são muito bons! Este é um dos melhores canais no youtube para se aprender de forma clara e descontraída sobre estatística e machine learning!\n",
    "\n",
    "Aqui, vamos ver o Random Forest em ação!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=6)]: Done 100 out of 100 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREINO:\n",
      "1.0\n",
      "TESTE:\n",
      "0.6658838753173882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from my_pipe import create_pipe\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def make_reports(pipe, X_train, X_test, y_train, y_test):\n",
    "    y_test_hat = pipe.predict(X_test)\n",
    "    y_train_hat = pipe.predict(X_train)\n",
    "\n",
    "    print(\"TREINO:\")\n",
    "    print(roc_auc_score(y_train, y_train_hat))\n",
    "    print(\"TESTE:\")\n",
    "    print(roc_auc_score(y_test, y_test_hat))\n",
    "\n",
    "df = pd.read_csv('data/bank_full.csv', sep=\";\")\n",
    "X = df.drop(columns='y')\n",
    "y = df['y'].astype(\"category\").cat.codes\n",
    "\n",
    "# redefinir pra poder alterar novamente\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42)\n",
    "\n",
    "numerical_columns = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_nominal_columns = [\"job\", \"marital\", \"poutcome\"]\n",
    "model = RandomForestClassifier(verbose=1, n_jobs=os.cpu_count() - 2)\n",
    "pipe = create_pipe(model, numerical_columns, categorical_nominal_columns)\n",
    "pipe.fit(X_train, y_train)\n",
    "make_reports(pipe, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "TREINO:\n",
      "0.7993742900724886\n",
      "TESTE:\n",
      "0.6537033432469022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model = RandomForestClassifier(verbose=0, n_jobs= os.cpu_count() - 2)\n",
    "pipe = create_pipe(model, numerical_columns, categorical_nominal_columns)\n",
    "\n",
    "param_grid = {'rf__n_estimators' : [100, 200],\n",
    "              'rf__max_depth' : [4,6,10,15]}\n",
    "\n",
    "grid = RandomizedSearchCV(pipe, \n",
    "                          param_grid,\n",
    "                          n_iter=5,\n",
    "                          scoring=\"roc_auc\", \n",
    "                          cv=5,  \n",
    "                          n_jobs=4, \n",
    "                          verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "make_reports(grid, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "## **Adaboost** <a class=\"anchor\" id=\"ada\"></a>\n",
    "\n",
    "O Adaboost significa **Adaptive Boosting**, e tem como procedimento geral **a criação sucessiva de árvores de um único nó (stumps - modelos fracos) que utiliza dos erros da árvore anterior para melhorar a próxima árvore**. As predições finais são feitas com base **nos pesos de cada stump**, cuja determinação faz parte do algoritmo.\n",
    "\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/1744/1*nJ5VrsiS1yaOR77d4h8gyw.png\" width=300></center>\n",
    "\n",
    "De forma resumida, as principais ideias por trás deste algoritmo são:\n",
    "\n",
    "- O algoritmo cria e combina um conjunto de **modelos fracos** (em geral, stumps);\n",
    "- Cada stump é criado **levando em consideração os erros do stump anterior**;\n",
    "- Alguns dos stumps têm **maior peso de decisão** do que outros na predição final;\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"https://www.researchgate.net/profile/Zhuo_Wang8/publication/288699540/figure/fig9/AS:668373486686246@1536364065786/Illustration-of-AdaBoost-algorithm-for-creating-a-strong-classifier-based-on-multiple.png\" width=500></center>\n",
    "\n",
    "<center><img src=\"https://static.packt-cdn.com/products/9781788295758/graphics/image_04_046-1.png\" width=400></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREINO:\n",
      "0.6588818245560081\n",
      "TESTE:\n",
      "0.6582651435655139\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=50)\n",
    "pipe = create_pipe(model, numerical_columns, categorical_nominal_columns)\n",
    "pipe.fit(X_train, y_train)\n",
    "make_reports(pipe, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "TREINO:\n",
      "0.664008103564873\n",
      "TESTE:\n",
      "0.6618306573946706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "pipe = create_pipe(model, numerical_columns, categorical_nominal_columns)\n",
    "\n",
    "param_grid = {'rf__n_estimators' : [50, 100, 200, 300]}\n",
    "\n",
    "grid = GridSearchCV(pipe, \n",
    "                    param_grid,\n",
    "                    scoring=\"roc_auc\", \n",
    "                    cv=5,  \n",
    "                    n_jobs=4, \n",
    "                    verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "make_reports(grid, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4) **Árvores de regressão** <a class=\"anchor\" id=\"regression\"></a>\n",
    "\n",
    "Alguns algoritmos de classificação podem ser utilizados como algoritmos de regressão, inclusive árvores de decisão!\n",
    "\n",
    "As **árvores de regressão** consistem em funções com valores discretos, similar a uma escada, onde cada degrau é o valor de uma folha. [Aqui](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html) há detalhes sobre a classe do sklearn; e [aqui](https://www.youtube.com/watch?v=g9c66TUylZ4) está o StatQuest sobre árvores de regressão!\n",
    "\n",
    "Considere o seguinte dataset:\n",
    "\n",
    "<center><img src='https://s3-sa-east-1.amazonaws.com/lcpi/800a4332-e709-4ea3-8c24-959c05c8fd65.png' width=500></center>\n",
    "\n",
    "O algoritmo irá obter os valores do target como sendo **a média dos valores de cada folha da árvore final**. \n",
    "\n",
    "Visualmente: \n",
    "\n",
    "<center><img src='https://s3-sa-east-1.amazonaws.com/lcpi/64cb4edd-20e1-486a-8fc9-60e60e1485d5.png' width=500></center>\n",
    "\n",
    "Para a escolha das melhores divisões: \n",
    "\n",
    "- o algoritmo percorre a médida entre cada par de pontos das features; \n",
    "- define estes valores como divisões (sequencialmente); \n",
    "- para cada divisão experimentada, o algoritmo calcula o MSE;\n",
    "- a melhor divisão é aquela que apresentar o menor erro!\n",
    "\n",
    "Visualmente:\n",
    "\n",
    "<center><img src='https://s3-sa-east-1.amazonaws.com/lcpi/be58ac8b-5c59-4b9f-be79-e000d060e9e3.png' width=500></center>\n",
    "\n",
    "<center><img src='https://s3-sa-east-1.amazonaws.com/lcpi/1f317afd-6119-41a5-849d-cee038403cf2.png' width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro exemplo de árvore de regressão treinada:\n",
    "\n",
    "<center><img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--YryIJN_o--/c_imagga_scale,f_auto,fl_progressive,h_900,q_auto,w_1600/https://thepracticaldev.s3.amazonaws.com/i/7oxf0e3cggdj9jayxeig.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer um modelo de árvore de regressão para precificação de casas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) **Exercicio** <a class=\"anchor\" id=\"exercicio\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/house_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_playground",
   "language": "python",
   "name": "venv_playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
